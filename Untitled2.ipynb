{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtJ3SY1LqKBXr5tuGkGM4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeylaY1996/sentiment-analysis-aws-reviews/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFjwov6sHxis",
        "outputId": "19e59834-6f69-4816-eea6-1e8facc88422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orijinal veri seti boyutu: (48487, 10)\n",
            "Yeni veri seti boyutu: (9697, 10)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Veri setini yükle\n",
        "csv_file_path = '/content/Reviews.csv'  # Dosya yolunuza göre güncelleyin\n",
        "df = pd.read_csv(csv_file_path, on_bad_lines='skip',quoting=3)  # daha yeni versiyonlar için\n",
        "# Veri setinin boyutunu yazdır\n",
        "print(\"Orijinal veri seti boyutu:\", df.shape)\n",
        "\n",
        "# %20 oranında rastgele bir alt küme seç\n",
        "sampled_df = df.sample(frac=0.2, random_state=42)  # random_state ile tekrarlanabilirlik sağlar\n",
        "\n",
        "# Yeni veri setinin boyutunu yazdır\n",
        "print(\"Yeni veri seti boyutu:\", sampled_df.shape)\n",
        "\n",
        "# İstediğiniz gibi veriyi kaydedin veya kullanın\n",
        "sampled_df.to_csv('sampled_reviews.csv', index=False)  # Yeni dosyayı kaydet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# NLTK stopwords ve punctuation yükle\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = string.punctuation\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Metni temizler: küçük harfe çevirir, noktalama işaretlerini kaldırır ve durak kelimeleri filtreler.\"\"\"\n",
        "    text = text.lower()  # Küçük harfe çevir\n",
        "    text = ''.join([char for char in text if char not in punctuation])  # Noktalama işaretlerini kaldır\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Durak kelimeleri filtrele\n",
        "    return text\n",
        "\n",
        "def prepare_data(csv_file):\n",
        "    \"\"\"Veri setini hazırlar: yükler, temizler ve etiketler.\"\"\"\n",
        "\n",
        "    # Veri setini yükle\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Gerekli sütunları seçin (örneğin: 'Text' ve 'Score')\n",
        "    df = df[['Text', 'Score']]\n",
        "\n",
        "    # Skorları ikili hale getirin (örneğin: 1-3 olumsuz, 4-5 olumlu)\n",
        "    df['Sentiment'] = df['Score'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "    # Yorumları temizle\n",
        "    df['cleaned_review'] = df['Text'].apply(clean_text)\n",
        "\n",
        "    # Sadece temizlenmiş yorumlar ve duygu etiketlerini içeren DataFrame döndür\n",
        "    return df[['cleaned_review', 'Sentiment']]\n",
        "\n",
        "# Kullanım örneği\n",
        "csv_file_path = '/content/sampled_reviews.csv'  # Dosya yolunuza göre güncelleyin\n",
        "prepared_data = prepare_data(csv_file_path)\n",
        "\n",
        "print(prepared_data.head())  # İlk 5 satırı yazdır"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40gjfNHgI8OF",
        "outputId": "6e35aca9-4e70-4c38-d839-f9f932ef3145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      cleaned_review  Sentiment\n",
            "0  369 per box stop shop also everyone keeps sayi...          1\n",
            "1  nice sweet treat nutritional value fantastic t...          1\n",
            "2  good deal cook using agave nectar due low suga...          1\n",
            "3  great deal via subscribe save set 2 boxes mont...          1\n",
            "4  mix spoonful wellness food toppermixer wellnes...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def svm_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde SVM ile duygu analizi yapar.\"\"\"\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF vektörleştirme\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # SVM modelini oluştur ve eğit\n",
        "    model = SVC(kernel='linear')\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Tahmin yap\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# SVM analizi\n",
        "accuracy, report = svm_sentiment_analysis(prepared_data)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdlly8k6JD-b",
        "outputId": "9887f3d9-2b5d-42b0-f5ee-c236b4270170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9072164948453608\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.56      0.66       311\n",
            "           1       0.92      0.97      0.95      1629\n",
            "\n",
            "    accuracy                           0.91      1940\n",
            "   macro avg       0.86      0.77      0.80      1940\n",
            "weighted avg       0.90      0.91      0.90      1940\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def naive_bayes_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde Naive Bayes ile duygu analizi yapar.\"\"\"\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF vektörleştirme\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # Naive Bayes modelini oluştur ve eğit\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Tahmin yap\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Sadece Naive Bayes analizi\n",
        "accuracy, report = naive_bayes_sentiment_analysis(prepared_data)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi1MXnl-Jdwt",
        "outputId": "a7c645b5-7a39-48de-88bc-511a2fb84ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8402061855670103\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.01       311\n",
            "           1       0.84      1.00      0.91      1629\n",
            "\n",
            "    accuracy                           0.84      1940\n",
            "   macro avg       0.92      0.50      0.46      1940\n",
            "weighted avg       0.87      0.84      0.77      1940\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Veri setini hazırla (daha önce hazırlandığını varsayıyoruz)\n",
        "# prepared_data, temizlenmiş yorumlar ve etiketler içermektedir\n",
        "\n",
        "def rnn_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde RNN (LSTM) ile duygu analizi yapar.\"\"\"\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # Metni sayısal verilere dönüştür\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)  # max_features ile öznitelik sayısını sınırlayın\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
        "    X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "    # RNN için veriyi uygun biçime getirin\n",
        "    max_length = 100  # Maximum uzunluk\n",
        "    X_train_padded = pad_sequences(X_train_tfidf, maxlen=max_length)\n",
        "    X_test_padded = pad_sequences(X_test_tfidf, maxlen=max_length)\n",
        "\n",
        "    # Modeli oluştur\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Modeli derle\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Modeli eğit\n",
        "    model.fit(X_train_padded, y_train, epochs=5, batch_size=64, validation_data=(X_test_padded, y_test))\n",
        "\n",
        "    # Test verisi üzerinde tahmin yap\n",
        "    y_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = np.mean(y_pred.flatten() == y_test)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# RNN analizi\n",
        "accuracy = rnn_sentiment_analysis(prepared_data)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIomJUx5JgtY",
        "outputId": "f1fcdde1-c849-4bf8-f572-8d93391a82bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - accuracy: 0.7938 - loss: 0.4970 - val_accuracy: 0.8397 - val_loss: 0.4406\n",
            "Epoch 2/5\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 323ms/step - accuracy: 0.8233 - loss: 0.4677 - val_accuracy: 0.8397 - val_loss: 0.4524\n",
            "Epoch 3/5\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 336ms/step - accuracy: 0.8174 - loss: 0.4787 - val_accuracy: 0.8397 - val_loss: 0.4403\n",
            "Epoch 4/5\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 305ms/step - accuracy: 0.8238 - loss: 0.4674 - val_accuracy: 0.8397 - val_loss: 0.4466\n",
            "Epoch 5/5\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.8215 - loss: 0.4710 - val_accuracy: 0.8397 - val_loss: 0.4408\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step\n",
            "Accuracy: 0.8396907216494846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Örnek bir duygu sözlüğü\n",
        "positive_words = {'good', 'great', 'excellent', 'happy', 'love', 'wonderful', 'amazing', 'fantastic'}\n",
        "negative_words = {'bad', 'terrible', 'horrible', 'sad', 'hate', 'awful', 'disappointing', 'poor'}\n",
        "\n",
        "def lexicon_based_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde lexicon-based duygu analizi yapar.\"\"\"\n",
        "\n",
        "    def get_sentiment(text):\n",
        "        \"\"\"Metindeki kelimeleri analiz ederek duygu puanı döndürür.\"\"\"\n",
        "        words = text.split()\n",
        "        score = 0\n",
        "\n",
        "        for word in words:\n",
        "            if word in positive_words:\n",
        "                score += 1  # Pozitif kelime varsa puanı artır\n",
        "            elif word in negative_words:\n",
        "                score -= 1  # Negatif kelime varsa puanı azalt\n",
        "\n",
        "        return 1 if score > 0 else 0  # Pozitif ise 1, olumsuz ise 0 döndür\n",
        "\n",
        "    # Her bir yorum için duygu analizi yap\n",
        "    df['Lexicon_Sentiment'] = df['cleaned_review'].apply(get_sentiment)\n",
        "\n",
        "    # Doğruluğu hesapla\n",
        "    accuracy = accuracy_score(df['Sentiment'], df['Lexicon_Sentiment'])\n",
        "\n",
        "    return df[['cleaned_review', 'Sentiment', 'Lexicon_Sentiment']], accuracy\n",
        "\n",
        "# Lexicon-based analizi\n",
        "lexicon_results, lexicon_accuracy = lexicon_based_sentiment_analysis(prepared_data)\n",
        "\n",
        "# Sonuçları yazdır\n",
        "print(\"Lexicon-Based Accuracy:\", lexicon_accuracy)\n",
        "print(lexicon_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlQj1UQXKOYn",
        "outputId": "a3d43c4c-5a64-47b0-9e8d-0a873edb48c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicon-Based Accuracy: 0.6329792719397752\n",
            "                                      cleaned_review  Sentiment  \\\n",
            "0  369 per box stop shop also everyone keeps sayi...          1   \n",
            "1  nice sweet treat nutritional value fantastic t...          1   \n",
            "2  good deal cook using agave nectar due low suga...          1   \n",
            "3  great deal via subscribe save set 2 boxes mont...          1   \n",
            "4  mix spoonful wellness food toppermixer wellnes...          1   \n",
            "\n",
            "   Lexicon_Sentiment  \n",
            "0                  0  \n",
            "1                  1  \n",
            "2                  1  \n",
            "3                  1  \n",
            "4                  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek bir özellik ve ona bağlı duygu sözlüğü\n",
        "aspects = {\n",
        "    'hız': {'good', 'great', 'fast', 'quick', 'excellent', 'amazing'},\n",
        "    'kalite': {'bad', 'poor', 'terrible', 'awful', 'good', 'excellent'}\n",
        "}\n",
        "\n",
        "def aspect_based_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde aspect-based duygu analizi yapar.\"\"\"\n",
        "\n",
        "    def get_aspect_sentiment(text):\n",
        "        \"\"\"Metindeki her bir özellik için duygu puanı döndürür.\"\"\"\n",
        "        words = text.split()\n",
        "        aspect_scores = {aspect: 0 for aspect in aspects.keys()}\n",
        "\n",
        "        for word in words:\n",
        "            for aspect, keywords in aspects.items():\n",
        "                if word in keywords:\n",
        "                    aspect_scores[aspect] += 1  # Pozitif kelime varsa puanı artır\n",
        "                elif word in [k for k in aspects[aspect] if k.startswith('not ')]:\n",
        "                    aspect_scores[aspect] -= 1  # Negatif kelime varsa puanı azalt\n",
        "\n",
        "        # Her bir bileşen için 1 veya 0 döndür\n",
        "        return int(aspect_scores['hız'] > 0), int(aspect_scores['kalite'] > 0)\n",
        "\n",
        "    # Her bir yorum için aspect-based duygu analizi yap\n",
        "    df[['Aspect_Hız', 'Aspect_Kalite']] = df['cleaned_review'].apply(get_aspect_sentiment).apply(pd.Series)\n",
        "\n",
        "    # Doğruluğu hesapla (hız veya kalite için olumlu tahmin)\n",
        "    accuracy_hız = accuracy_score(df['Sentiment'], df['Aspect_Hız'])\n",
        "    accuracy_kalite = accuracy_score(df['Sentiment'], df['Aspect_Kalite'])\n",
        "\n",
        "    return df[['cleaned_review', 'Sentiment', 'Aspect_Hız', 'Aspect_Kalite']], accuracy_hız, accuracy_kalite\n",
        "\n",
        "# Aspect-based analizi\n",
        "aspect_results, aspect_accuracy_hız, aspect_accuracy_kalite = aspect_based_sentiment_analysis(prepared_data)\n",
        "\n",
        "# Sonuçları yazdır\n",
        "print(\"Aspect-Based Accuracy (Hız):\", aspect_accuracy_hız)\n",
        "print(\"Aspect-Based Accuracy (Kalite):\", aspect_accuracy_kalite)\n",
        "print(aspect_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe_9NYHiLPvZ",
        "outputId": "d1988c39-faf2-42c3-ae4c-dd11e3086a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect-Based Accuracy (Hız): 0.5266577291945963\n",
            "Aspect-Based Accuracy (Kalite): 0.33051459214189954\n",
            "                                      cleaned_review  Sentiment  Aspect_Hız  \\\n",
            "0  369 per box stop shop also everyone keeps sayi...          1           0   \n",
            "1  nice sweet treat nutritional value fantastic t...          1           0   \n",
            "2  good deal cook using agave nectar due low suga...          1           1   \n",
            "3  great deal via subscribe save set 2 boxes mont...          1           1   \n",
            "4  mix spoonful wellness food toppermixer wellnes...          1           0   \n",
            "\n",
            "   Aspect_Kalite  \n",
            "0              0  \n",
            "1              0  \n",
            "2              1  \n",
            "3              0  \n",
            "4              0  \n"
          ]
        }
      ]
    }
  ]
}