{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhZiG0IhSTjHE9SzoJEur0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeylaY1996/sentiment-analysis-aws-reviews/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFjwov6sHxis",
        "outputId": "b34182ee-f9af-4ad6-99c6-ec4abb8ea621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orijinal veri seti boyutu: (2851, 10)\n",
            "Yeni veri seti boyutu: (570, 10)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Veri setini yükle\n",
        "csv_file_path = '/content/Reviews.csv'  # Dosya yolunuza göre güncelleyin\n",
        "df = pd.read_csv(csv_file_path, on_bad_lines='skip',quoting=3)  # daha yeni versiyonlar için\n",
        "# Veri setinin boyutunu yazdır\n",
        "print(\"Orijinal veri seti boyutu:\", df.shape)\n",
        "\n",
        "# %20 oranında rastgele bir alt küme seç\n",
        "sampled_df = df.sample(frac=0.2, random_state=42)  # random_state ile tekrarlanabilirlik sağlar\n",
        "\n",
        "# Yeni veri setinin boyutunu yazdır\n",
        "print(\"Yeni veri seti boyutu:\", sampled_df.shape)\n",
        "\n",
        "# İstediğiniz gibi veriyi kaydedin veya kullanın\n",
        "sampled_df.to_csv('sampled_reviews.csv', index=False)  # Yeni dosyayı kaydet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# NLTK stopwords ve punctuation yükle\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = string.punctuation\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Metni temizler: küçük harfe çevirir, noktalama işaretlerini kaldırır ve durak kelimeleri filtreler.\"\"\"\n",
        "    text = text.lower()  # Küçük harfe çevir\n",
        "    text = ''.join([char for char in text if char not in punctuation])  # Noktalama işaretlerini kaldır\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Durak kelimeleri filtrele\n",
        "    return text\n",
        "\n",
        "def prepare_data(csv_file):\n",
        "    \"\"\"Veri setini hazırlar: yükler, temizler ve etiketler.\"\"\"\n",
        "\n",
        "    # Veri setini yükle\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Gerekli sütunları seçin (örneğin: 'Text' ve 'Score')\n",
        "    df = df[['Text', 'Score']]\n",
        "\n",
        "    # Skorları ikili hale getirin (örneğin: 1-3 olumsuz, 4-5 olumlu)\n",
        "    df['Sentiment'] = df['Score'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "    # Yorumları temizle\n",
        "    df['cleaned_review'] = df['Text'].apply(clean_text)\n",
        "\n",
        "    # Sadece temizlenmiş yorumlar ve duygu etiketlerini içeren DataFrame döndür\n",
        "    return df[['cleaned_review', 'Sentiment']]\n",
        "\n",
        "# Kullanım örneği\n",
        "csv_file_path = '/content/sampled_reviews.csv'  # Dosya yolunuza göre güncelleyin\n",
        "prepared_data = prepare_data(csv_file_path)\n",
        "\n",
        "print(prepared_data.head())  # İlk 5 satırı yazdır"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40gjfNHgI8OF",
        "outputId": "6f8046f5-13a5-4f26-e7fa-fb09c5bbee0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      cleaned_review  Sentiment\n",
            "0  natural real food see difference cat loves muc...          1\n",
            "1  happy product cooked potatoes flat didnt look ...          0\n",
            "2  jelly tastes heavenly wont find anything good ...          1\n",
            "3  wonderful dark chocolate flavor much deeper fl...          1\n",
            "4  excellent service goat milk delivered premium ...          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "def svm_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde SVM ile duygu analizi yapar ve sonuçları döner.\"\"\"\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF vektörleştirme\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # SVM modelini oluştur ve eğit\n",
        "    model = SVC(kernel='linear')\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Tahmin yap\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Karmaşıklık matrisi\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report, cm\n",
        "\n",
        "# SVM analizi\n",
        "accuracy, report, cm = svm_sentiment_analysis(prepared_data)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdlly8k6JD-b",
        "outputId": "ddeceaa6-cd06-48cc-eaf2-68e2c776901b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8245614035087719\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        22\n",
            "           1       0.82      1.00      0.90        92\n",
            "\n",
            "    accuracy                           0.82       114\n",
            "   macro avg       0.91      0.55      0.53       114\n",
            "weighted avg       0.86      0.82      0.76       114\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 2 20]\n",
            " [ 0 92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "def naive_bayes_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde Naive Bayes ile duygu analizi yapar ve sonuçları döner.\"\"\"\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF vektörleştirme\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # Naive Bayes modelini oluştur ve eğit\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Tahmin yap\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, zero_division=1)\n",
        "\n",
        "    # Karmaşıklık matrisi\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report, cm\n",
        "\n",
        "# Naive Bayes analizi\n",
        "accuracy, report, cm = naive_bayes_sentiment_analysis(prepared_data)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi1MXnl-Jdwt",
        "outputId": "e764343f-84bd-48a1-bde9-e53b98c14cb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8070175438596491\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00        22\n",
            "           1       0.81      1.00      0.89        92\n",
            "\n",
            "    accuracy                           0.81       114\n",
            "   macro avg       0.90      0.50      0.45       114\n",
            "weighted avg       0.84      0.81      0.72       114\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 0 22]\n",
            " [ 0 92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# RNN model fonksiyonu\n",
        "def rnn_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde RNN (LSTM) ile duygu analizi yapar ve sonuçları döner.\"\"\"\n",
        "\n",
        "    # Etiketleri sayısal değerlere dönüştür\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['Sentiment'] = label_encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "    # Veriyi eğitim ve test setine ayır\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # Metni sayısal verilere dönüştür\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)  # max_features ile öznitelik sayısını sınırlayın\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
        "    X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "    # RNN için veriyi uygun biçime getirin\n",
        "    max_length = 100  # Maximum uzunluk\n",
        "    X_train_padded = pad_sequences(X_train_tfidf, maxlen=max_length)\n",
        "    X_test_padded = pad_sequences(X_test_tfidf, maxlen=max_length)\n",
        "\n",
        "    # Modeli oluştur\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=5000, output_dim=128))  # input_length kaldırıldı\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Modeli derle\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Modeli eğit\n",
        "    model.fit(X_train_padded, y_train, epochs=5, batch_size=64, validation_data=(X_test_padded, y_test))\n",
        "\n",
        "    # Test verisi üzerinde tahmin yap\n",
        "    y_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "    # Sonuçları değerlendir\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    report = classification_report(y_test, y_pred, zero_division=1)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report, cm\n",
        "\n",
        "# RNN analizi\n",
        "accuracy, report, cm = rnn_sentiment_analysis(prepared_data)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIomJUx5JgtY",
        "outputId": "85ea651f-0028-477d-fdc6-8c889db110c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 268ms/step - accuracy: 0.8368 - loss: 0.5881 - val_accuracy: 0.8070 - val_loss: 0.5055\n",
            "Epoch 2/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 0.8007 - loss: 0.5226 - val_accuracy: 0.8070 - val_loss: 0.4907\n",
            "Epoch 3/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - accuracy: 0.8222 - loss: 0.4681 - val_accuracy: 0.8070 - val_loss: 0.5067\n",
            "Epoch 4/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - accuracy: 0.8285 - loss: 0.4686 - val_accuracy: 0.8070 - val_loss: 0.4925\n",
            "Epoch 5/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 403ms/step - accuracy: 0.8172 - loss: 0.4829 - val_accuracy: 0.8070 - val_loss: 0.4917\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step\n",
            "Accuracy: 0.8070175438596491\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00        22\n",
            "           1       0.81      1.00      0.89        92\n",
            "\n",
            "    accuracy                           0.81       114\n",
            "   macro avg       0.90      0.50      0.45       114\n",
            "weighted avg       0.84      0.81      0.72       114\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 0 22]\n",
            " [ 0 92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Örnek bir duygu sözlüğü\n",
        "positive_words = {'good', 'great', 'excellent', 'happy', 'love', 'wonderful', 'amazing', 'fantastic'}\n",
        "negative_words = {'bad', 'terrible', 'horrible', 'sad', 'hate', 'awful', 'disappointing', 'poor'}\n",
        "\n",
        "def lexicon_based_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde lexicon-based duygu analizi yapar.\"\"\"\n",
        "\n",
        "    def get_sentiment(text):\n",
        "        \"\"\"Metindeki kelimeleri analiz ederek duygu puanı döndürür.\"\"\"\n",
        "        words = text.split()\n",
        "        score = 0\n",
        "\n",
        "        for word in words:\n",
        "            if word in positive_words:\n",
        "                score += 1  # Pozitif kelime varsa puanı artır\n",
        "            elif word in negative_words:\n",
        "                score -= 1  # Negatif kelime varsa puanı azalt\n",
        "\n",
        "        return 1 if score > 0 else 0  # Pozitif ise 1, olumsuz ise 0 döndür\n",
        "\n",
        "    # Her bir yorum için duygu analizi yap\n",
        "    df['Lexicon_Sentiment'] = df['cleaned_review'].apply(get_sentiment)\n",
        "\n",
        "    # Doğruluğu hesapla\n",
        "    accuracy = accuracy_score(df['Sentiment'], df['Lexicon_Sentiment'])\n",
        "\n",
        "    # Sınıflandırma raporu ve karmaşıklık matrisi\n",
        "    report = classification_report(df['Sentiment'], df['Lexicon_Sentiment'])\n",
        "    cm = confusion_matrix(df['Sentiment'], df['Lexicon_Sentiment'])\n",
        "\n",
        "    return df[['cleaned_review', 'Sentiment', 'Lexicon_Sentiment']], accuracy, report, cm\n",
        "\n",
        "# Lexicon-based analizi\n",
        "lexicon_results, lexicon_accuracy, lexicon_report, lexicon_cm = lexicon_based_sentiment_analysis(prepared_data)\n",
        "\n",
        "# Sonuçları yazdır\n",
        "print(\"Lexicon-Based Accuracy:\", lexicon_accuracy)\n",
        "print(lexicon_report)\n",
        "print(\"Confusion Matrix:\\n\", lexicon_cm)\n",
        "print(lexicon_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlQj1UQXKOYn",
        "outputId": "60e09583-3cf9-4a9a-9de4-87dc452d0c93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicon-Based Accuracy: 0.6228070175438597\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.76      0.42       101\n",
            "           1       0.92      0.59      0.72       469\n",
            "\n",
            "    accuracy                           0.62       570\n",
            "   macro avg       0.60      0.68      0.57       570\n",
            "weighted avg       0.81      0.62      0.67       570\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 77  24]\n",
            " [191 278]]\n",
            "                                      cleaned_review  Sentiment  \\\n",
            "0  natural real food see difference cat loves muc...          1   \n",
            "1  happy product cooked potatoes flat didnt look ...          0   \n",
            "2  jelly tastes heavenly wont find anything good ...          1   \n",
            "3  wonderful dark chocolate flavor much deeper fl...          1   \n",
            "4  excellent service goat milk delivered premium ...          1   \n",
            "\n",
            "   Lexicon_Sentiment  \n",
            "0                  0  \n",
            "1                  1  \n",
            "2                  1  \n",
            "3                  1  \n",
            "4                  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Örnek bir özellik ve ona bağlı duygu sözlüğü\n",
        "aspects = {\n",
        "    'hız': {'good', 'great', 'fast', 'quick', 'excellent', 'amazing', 'slow', 'not fast'},\n",
        "    'kalite': {'bad', 'poor', 'terrible', 'awful', 'good', 'excellent', 'not good'}\n",
        "}\n",
        "\n",
        "def aspect_based_sentiment_analysis(df):\n",
        "    \"\"\"Verilen veri setinde aspect-based duygu analizi yapar.\"\"\"\n",
        "\n",
        "    def get_aspect_sentiment(text):\n",
        "        \"\"\"Metindeki her bir özellik için duygu puanı döndürür.\"\"\"\n",
        "        words = text.split()\n",
        "        aspect_scores = {aspect: 0 for aspect in aspects.keys()}\n",
        "\n",
        "        for word in words:\n",
        "            for aspect, keywords in aspects.items():\n",
        "                if word in keywords:\n",
        "                    # Pozitif kelime için puanı artır\n",
        "                    aspect_scores[aspect] += 1 if 'not' not in word else -1\n",
        "\n",
        "        # Her bir bileşen için 1 (olumlu) veya 0 (olumsuz) döndür\n",
        "        return int(aspect_scores['hız'] > 0), int(aspect_scores['kalite'] > 0)\n",
        "\n",
        "    # Her bir yorum için aspect-based duygu analizi yap\n",
        "    df[['Aspect_Hız', 'Aspect_Kalite']] = df['cleaned_review'].apply(get_aspect_sentiment).apply(pd.Series)\n",
        "\n",
        "    # Doğruluk hesapla\n",
        "    accuracy_hız = accuracy_score(df['Sentiment'], df['Aspect_Hız'])\n",
        "    accuracy_kalite = accuracy_score(df['Sentiment'], df['Aspect_Kalite'])\n",
        "\n",
        "    # Sınıflandırma raporu ve karmaşıklık matrisleri\n",
        "    report_hız = classification_report(df['Sentiment'], df['Aspect_Hız'])\n",
        "    cm_hız = confusion_matrix(df['Sentiment'], df['Aspect_Hız'])\n",
        "\n",
        "    report_kalite = classification_report(df['Sentiment'], df['Aspect_Kalite'])\n",
        "    cm_kalite = confusion_matrix(df['Sentiment'], df['Aspect_Kalite'])\n",
        "\n",
        "    return df[['cleaned_review', 'Sentiment', 'Aspect_Hız', 'Aspect_Kalite']], accuracy_hız, accuracy_kalite, report_hız, report_kalite, cm_hız, cm_kalite\n",
        "\n",
        "# Aspect-based analizi\n",
        "aspect_results, aspect_accuracy_hız, aspect_accuracy_kalite, report_hız, report_kalite, cm_hız, cm_kalite = aspect_based_sentiment_analysis(prepared_data)\n",
        "\n",
        "# Sonuçları yazdır\n",
        "print(\"Aspect-Based Accuracy (Hız):\", aspect_accuracy_hız)\n",
        "print(report_hız)\n",
        "print(\"Confusion Matrix (Hız):\\n\", cm_hız)\n",
        "\n",
        "print(\"Aspect-Based Accuracy (Kalite):\", aspect_accuracy_kalite)\n",
        "print(report_kalite)\n",
        "print(\"Confusion Matrix (Kalite):\\n\", cm_kalite)\n",
        "\n",
        "print(aspect_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe_9NYHiLPvZ",
        "outputId": "3e73c5e8-7931-4fd8-d8ac-d77b51d0b462"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect-Based Accuracy (Hız): 0.5333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.77      0.37       101\n",
            "           1       0.91      0.48      0.63       469\n",
            "\n",
            "    accuracy                           0.53       570\n",
            "   macro avg       0.58      0.63      0.50       570\n",
            "weighted avg       0.79      0.53      0.58       570\n",
            "\n",
            "Confusion Matrix (Hız):\n",
            " [[ 78  23]\n",
            " [243 226]]\n",
            "Aspect-Based Accuracy (Kalite): 0.356140350877193\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.78      0.30       101\n",
            "           1       0.85      0.26      0.40       469\n",
            "\n",
            "    accuracy                           0.36       570\n",
            "   macro avg       0.52      0.52      0.35       570\n",
            "weighted avg       0.73      0.36      0.39       570\n",
            "\n",
            "Confusion Matrix (Kalite):\n",
            " [[ 79  22]\n",
            " [345 124]]\n",
            "                                      cleaned_review  Sentiment  Aspect_Hız  \\\n",
            "0  natural real food see difference cat loves muc...          1           0   \n",
            "1  happy product cooked potatoes flat didnt look ...          0           0   \n",
            "2  jelly tastes heavenly wont find anything good ...          1           1   \n",
            "3  wonderful dark chocolate flavor much deeper fl...          1           1   \n",
            "4  excellent service goat milk delivered premium ...          1           1   \n",
            "\n",
            "   Aspect_Kalite  \n",
            "0              0  \n",
            "1              0  \n",
            "2              1  \n",
            "3              1  \n",
            "4              1  \n"
          ]
        }
      ]
    }
  ]
}
